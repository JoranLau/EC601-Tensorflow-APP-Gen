{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xieyn\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a short configuration name [default = \"default\"]: \n",
      "Continue previous training? [Y/n]: n\n",
      "WARNING:tensorflow:From C:\\Users\\xieyn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:187: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\xieyn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-1-c3711544bb03>:234: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "Iteration: 250, Loss: 9.770, Accuracy: 0.0058\n",
      "Iteration: 500, Loss: 9.603, Accuracy: 0.0077\n",
      "Iteration: 750, Loss: 9.455, Accuracy: 0.0088\n",
      "Iteration: 1000, Loss: 9.282, Accuracy: 0.0137\n",
      "Iteration: 1250, Loss: 9.104, Accuracy: 0.0174\n",
      "Iteration: 1500, Loss: 8.939, Accuracy: 0.0221\n",
      "Iteration: 1750, Loss: 8.771, Accuracy: 0.0292\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/vgg_16/default/model-2000\n",
      "Validation. Loss: 8.393, Accuracy: 0.0467\n",
      "Iteration: 2000, Loss: 8.579, Accuracy: 0.0349\n",
      "Iteration: 2250, Loss: 8.373, Accuracy: 0.0422\n",
      "Iteration: 2500, Loss: 8.196, Accuracy: 0.0533\n",
      "Iteration: 2750, Loss: 8.016, Accuracy: 0.0591\n",
      "Iteration: 3000, Loss: 7.861, Accuracy: 0.0689\n",
      "Iteration: 3250, Loss: 7.713, Accuracy: 0.0762\n",
      "Iteration: 3500, Loss: 7.564, Accuracy: 0.0857\n",
      "Iteration: 3750, Loss: 7.454, Accuracy: 0.0886\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/vgg_16/default/model-4000\n",
      "Validation. Loss: 7.134, Accuracy: 0.1241\n",
      "Iteration: 4000, Loss: 7.340, Accuracy: 0.0994\n",
      "Iteration: 4250, Loss: 7.199, Accuracy: 0.1086\n",
      "Iteration: 4500, Loss: 7.072, Accuracy: 0.1106\n",
      "Iteration: 4750, Loss: 6.937, Accuracy: 0.1279\n",
      "Iteration: 5000, Loss: 6.794, Accuracy: 0.1384\n",
      "Iteration: 5250, Loss: 6.727, Accuracy: 0.1388\n",
      "Iteration: 5500, Loss: 6.614, Accuracy: 0.1444\n",
      "Iteration: 5750, Loss: 6.520, Accuracy: 0.1501\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/vgg_16/default/model-6000\n",
      "Validation. Loss: 6.199, Accuracy: 0.1888\n",
      "Iteration: 6000, Loss: 6.449, Accuracy: 0.1569\n",
      "Iteration: 6250, Loss: 6.325, Accuracy: 0.1723\n",
      "Iteration: 6500, Loss: 6.188, Accuracy: 0.1796\n",
      "Iteration: 6750, Loss: 6.109, Accuracy: 0.1858\n",
      "Iteration: 7000, Loss: 6.054, Accuracy: 0.1906\n",
      "Iteration: 7250, Loss: 5.969, Accuracy: 0.1973\n",
      "Iteration: 7500, Loss: 5.904, Accuracy: 0.1999\n",
      "Iteration: 7750, Loss: 5.842, Accuracy: 0.2006\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/vgg_16/default/model-8000\n",
      "Validation. Loss: 5.587, Accuracy: 0.2394\n",
      "Iteration: 8000, Loss: 5.702, Accuracy: 0.2196\n",
      "Iteration: 8250, Loss: 5.668, Accuracy: 0.2175\n",
      "Iteration: 8500, Loss: 5.580, Accuracy: 0.2247\n",
      "Iteration: 8750, Loss: 5.528, Accuracy: 0.2243\n",
      "Iteration: 9000, Loss: 5.512, Accuracy: 0.2264\n",
      "Iteration: 9250, Loss: 5.413, Accuracy: 0.2375\n",
      "Iteration: 9500, Loss: 5.273, Accuracy: 0.2573\n",
      "Iteration: 9750, Loss: 5.241, Accuracy: 0.2580\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/vgg_16/default/model-10000\n",
      "Validation. Loss: 5.071, Accuracy: 0.2796\n",
      "Iteration: 10000, Loss: 5.211, Accuracy: 0.2549\n",
      "Iteration: 10250, Loss: 5.177, Accuracy: 0.2584\n",
      "Iteration: 10500, Loss: 5.123, Accuracy: 0.2612\n",
      "Iteration: 10750, Loss: 5.087, Accuracy: 0.2631\n",
      "Iteration: 11000, Loss: 4.980, Accuracy: 0.2788\n",
      "Iteration: 11250, Loss: 4.912, Accuracy: 0.2827\n",
      "Iteration: 11500, Loss: 4.888, Accuracy: 0.2844\n",
      "Iteration: 11750, Loss: 4.855, Accuracy: 0.2879\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/vgg_16/default/model-12000\n",
      "Validation. Loss: 4.736, Accuracy: 0.3041\n",
      "Iteration: 12000, Loss: 4.826, Accuracy: 0.2913\n",
      "Iteration: 12250, Loss: 4.779, Accuracy: 0.2925\n",
      "Iteration: 12500, Loss: 4.714, Accuracy: 0.3002\n",
      "Iteration: 12750, Loss: 4.636, Accuracy: 0.3099\n",
      "Iteration: 13000, Loss: 4.611, Accuracy: 0.3106\n",
      "Iteration: 13250, Loss: 4.592, Accuracy: 0.3134\n",
      "Iteration: 13500, Loss: 4.578, Accuracy: 0.3137\n",
      "Iteration: 13750, Loss: 4.531, Accuracy: 0.3169\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/vgg_16/default/model-14000\n",
      "Validation. Loss: 4.484, Accuracy: 0.3255\n",
      "Iteration: 14000, Loss: 4.518, Accuracy: 0.3166\n",
      "Iteration: 14250, Loss: 4.404, Accuracy: 0.3300\n",
      "Iteration: 14500, Loss: 4.329, Accuracy: 0.3438\n",
      "Iteration: 14750, Loss: 4.373, Accuracy: 0.3322\n",
      "Iteration: 15000, Loss: 4.337, Accuracy: 0.3321\n",
      "Iteration: 15250, Loss: 4.331, Accuracy: 0.3324\n",
      "Iteration: 15500, Loss: 4.307, Accuracy: 0.3410\n",
      "Iteration: 15750, Loss: 4.215, Accuracy: 0.3574\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/vgg_16/default/model-16000\n",
      "Validation. Loss: 4.214, Accuracy: 0.3590\n",
      "Iteration: 16000, Loss: 4.170, Accuracy: 0.3576\n",
      "Iteration: 16250, Loss: 4.179, Accuracy: 0.3490\n",
      "Iteration: 16500, Loss: 4.152, Accuracy: 0.3601\n",
      "Iteration: 16750, Loss: 4.163, Accuracy: 0.3509\n",
      "Iteration: 17000, Loss: 4.134, Accuracy: 0.3593\n",
      "Iteration: 17250, Loss: 4.040, Accuracy: 0.3759\n",
      "Iteration: 17500, Loss: 3.985, Accuracy: 0.3796\n",
      "Iteration: 17750, Loss: 4.016, Accuracy: 0.3713\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/vgg_16/default/model-18000\n",
      "Validation. Loss: 4.078, Accuracy: 0.3672\n",
      "Iteration: 18000, Loss: 4.012, Accuracy: 0.3758\n",
      "Iteration: 18250, Loss: 3.969, Accuracy: 0.3837\n",
      "Iteration: 18500, Loss: 3.951, Accuracy: 0.3848\n",
      "Iteration: 18750, Loss: 3.944, Accuracy: 0.3869\n",
      "Iteration: 19000, Loss: 3.843, Accuracy: 0.3964\n",
      "Iteration: 19250, Loss: 3.874, Accuracy: 0.3899\n",
      "Iteration: 19500, Loss: 3.875, Accuracy: 0.3909\n",
      "Iteration: 19750, Loss: 3.843, Accuracy: 0.3964\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/vgg_16/default/model-20000\n",
      "Validation. Loss: 3.906, Accuracy: 0.3924\n",
      "Iteration: 20000, Loss: 3.845, Accuracy: 0.3986\n",
      "Iteration: 20250, Loss: 3.853, Accuracy: 0.3936\n",
      "Iteration: 20500, Loss: 3.711, Accuracy: 0.4162\n",
      "Iteration: 20750, Loss: 3.746, Accuracy: 0.4128\n",
      "Iteration: 21000, Loss: 3.768, Accuracy: 0.4044\n",
      "Iteration: 21250, Loss: 3.759, Accuracy: 0.4099\n",
      "Iteration: 21500, Loss: 3.751, Accuracy: 0.4153\n",
      "Iteration: 21750, Loss: 3.748, Accuracy: 0.4098\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/vgg_16/default/model-22000\n",
      "Validation. Loss: 3.808, Accuracy: 0.4105\n",
      "Iteration: 22000, Loss: 3.624, Accuracy: 0.4344\n",
      "Iteration: 22250, Loss: 3.614, Accuracy: 0.4323\n",
      "Iteration: 22500, Loss: 3.656, Accuracy: 0.4263\n",
      "Iteration: 22750, Loss: 3.629, Accuracy: 0.4322\n",
      "Iteration: 23000, Loss: 3.665, Accuracy: 0.4263\n"
     ]
    }
   ],
   "source": [
    "from vgg_16 import *\n",
    "# from logistic_regression import *\n",
    "# from single_layer_nn import *\n",
    "from metrics import *\n",
    "from losses import *\n",
    "from input_pipe import *\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "\n",
    "class TrainConfig(object):\n",
    "  \"\"\"Training configuration\"\"\"\n",
    "  batch_size = 64\n",
    "  num_epochs = 50\n",
    "  summary_interval = 250\n",
    "  eval_interval = 2000  # must be integer multiple of summary_interval\n",
    "  lr = 0.01  # learning rate\n",
    "  reg = 5e-4  # regularization\n",
    "  momentum = 0.9\n",
    "  dropout_keep_prob = 0.5\n",
    "  model_name = 'vgg_16'  # choose model\n",
    "  model = staticmethod(globals()[model_name])  # gets model by name\n",
    "\n",
    "\n",
    "class TrainControl(object):\n",
    "  \"\"\"Basic training control\n",
    "  Decreases learning rate (lr), terminates training after 3 lr decreases\n",
    "  Track validation accuracy, decrease lr by 1/5th when:\n",
    "    1. validation accuracy worsens\n",
    "    2. less than 0.2% absolute improvement last 3 iterations\n",
    "  \"\"\"\n",
    "  def __init__(self, lr):\n",
    "    self.val_accs = []\n",
    "    self.lr = lr\n",
    "    self.num_lr_updates = 0\n",
    "    self.lr_factor = 1/5\n",
    "\n",
    "  def add_val_acc(self, loss):\n",
    "    self.val_accs.append(loss)\n",
    "\n",
    "  def update_lr(self, sess):\n",
    "    if len(self.val_accs) < 3:\n",
    "      return\n",
    "    decrease = False\n",
    "    # decrease LR if validation acc worsens\n",
    "    if self.val_accs[-1] < max(self.val_accs):\n",
    "      decrease = True\n",
    "    avg_2 = (self.val_accs[-2] + self.val_accs[-3]) / 2\n",
    "    # decrease LR if validation accuracy doesn't improve by 0.2% (absolute)\n",
    "    if abs(self.val_accs[-1] - avg_2) < 0.002:\n",
    "      decrease = True\n",
    "    if decrease:\n",
    "      old_lr = sess.run(self.lr)\n",
    "      self.lr.load(old_lr * self.lr_factor)\n",
    "      self.num_lr_updates += 1\n",
    "      print('*** New learning rate: {}'.format(old_lr * self.lr_factor))\n",
    "\n",
    "  def done(self):\n",
    "    if self.num_lr_updates > 3:  # terminate training after 3 lr decreases\n",
    "      return True\n",
    "    else:\n",
    "      return False\n",
    "\n",
    "\n",
    "def optimizer(loss, config):\n",
    "  \"\"\"Add training operation, global_step and learning rate variable to Graph\n",
    "  Args:\n",
    "    loss: model loss tensor\n",
    "    config: training configuration object\n",
    "  Returns:\n",
    "    (train_op, global_step, lr)\n",
    "  \"\"\"\n",
    "  lr = tf.Variable(config.lr, trainable=False, dtype=tf.float32)\n",
    "  global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "  optim = tf.train.MomentumOptimizer(lr, config.momentum,\n",
    "                                     use_nesterov=True)\n",
    "  train_op = optim.minimize(loss, global_step=global_step)\n",
    "\n",
    "  return train_op, global_step, lr\n",
    "\n",
    "\n",
    "def get_logdir():\n",
    "  \"\"\"Return unique logdir based on datetime\"\"\"\n",
    "  now = datetime.utcnow().strftime(\"%m%d%H%M%S\")\n",
    "  logdir = \"run-{}/\".format(now)\n",
    "\n",
    "  return logdir\n",
    "\n",
    "\n",
    "def model(mode, config):\n",
    "  \"\"\"Pull it all together: input queue, inference model and loss functions\n",
    "  Args:\n",
    "    mode: 'train' or 'val'\n",
    "    config: model configuration object\n",
    "  Returns:\n",
    "    loss and accuracy tensors\n",
    "  \"\"\"\n",
    "  # preprocess images on cpu - send to gpu as uint8 for speed\n",
    "  with tf.device('/cpu:0'):\n",
    "    imgs, labels = batch_q(mode, config)\n",
    "\n",
    "  logits = config.model(imgs, config)\n",
    "  softmax_ce_loss(logits, labels)\n",
    "  acc = accuracy(logits, labels)\n",
    "  total_loss = tf.add_n(tf.get_collection(tf.GraphKeys.LOSSES), name='total_loss')\n",
    "  total_loss += tf.add_n(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES),\n",
    "                         name='total_loss') * config.reg\n",
    "  for l2 in tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES):\n",
    "    # add l2 loss histograms to TensorBoard and cleanup var names\n",
    "    name = 'l2_loss_' + l2.name.split('/')[0]\n",
    "    tf.summary.histogram(name, l2)\n",
    "\n",
    "  return total_loss, acc\n",
    "\n",
    "\n",
    "def evaluate(ckpt):\n",
    "  \"\"\"Load checkpoint and run on validation set\"\"\"\n",
    "  config = TrainConfig()\n",
    "  config.dropout_keep_prob = 1.0  # disable dropout for validation\n",
    "  config.num_epochs = 1\n",
    "  accs, losses = [], []\n",
    "\n",
    "  with tf.Graph().as_default():\n",
    "    loss, acc = model('val', config)\n",
    "    saver = tf.train.Saver()\n",
    "    init = tf.group(tf.global_variables_initializer(),\n",
    "                    tf.local_variables_initializer())\n",
    "    with tf.Session() as sess:\n",
    "      init.run()\n",
    "      saver.restore(sess, ckpt)\n",
    "      coord = tf.train.Coordinator()\n",
    "      threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "      try:\n",
    "        while not coord.should_stop():\n",
    "          step_loss, step_acc = sess.run([loss, acc])\n",
    "          accs.append(step_acc)\n",
    "          losses.append(step_loss)\n",
    "      except tf.errors.OutOfRangeError as e:\n",
    "        coord.request_stop(e)\n",
    "      finally:\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "  mean_loss, mean_acc = np.mean(losses), np.mean(accs)\n",
    "  print('Validation. Loss: {:.3f}, Accuracy: {:.4f}'.\n",
    "        format(mean_loss, mean_acc))\n",
    "\n",
    "  return mean_loss, mean_acc\n",
    "\n",
    "\n",
    "def options(config):\n",
    "  \"\"\"Get user input on training options\"\"\"\n",
    "  q = input('Enter a short configuration name [default = \"default\"]: ')\n",
    "  if len(q) == 0:\n",
    "    q = 'default'\n",
    "  config.config_name = q\n",
    "  # tensorboard and checkpoint log directory names\n",
    "  ckpt_path = 'checkpoints/' + config.model_name + '/' + config.config_name\n",
    "  tflog_path = ('tf_logs/' + config.model_name + '/' +\n",
    "                config.config_name + '/' + get_logdir())\n",
    "  checkpoint = None\n",
    "  # TODO: spaghetti mess, clean up:\n",
    "  if not os.path.isdir(ckpt_path):\n",
    "    os.makedirs(ckpt_path)\n",
    "    filenames = glob.glob('*.py')\n",
    "    for filename in filenames:\n",
    "      shutil.copy(filename, ckpt_path)\n",
    "    return False, ckpt_path, tflog_path, checkpoint\n",
    "  else:\n",
    "    filenames = glob.glob('*.py')\n",
    "    for filename in filenames:\n",
    "      shutil.copy(filename, ckpt_path)\n",
    "    while True:\n",
    "      q1 = input('Continue previous training? [Y/n]: ')\n",
    "      if len(q1) == 0 or q1 == 'n' or q1 == 'Y':\n",
    "        break\n",
    "    if q1 == 'n':\n",
    "      return False, ckpt_path, tflog_path, checkpoint\n",
    "    else:\n",
    "      q2 = input('Enter checkpoint name [defaults to most recent]: ')\n",
    "      if len(q2) == 0:\n",
    "        checkpoint = tf.train.latest_checkpoint(ckpt_path)\n",
    "      else:\n",
    "        checkpoint = ckpt_path + '/' + q2\n",
    "      return True, ckpt_path, tflog_path, checkpoint\n",
    "\n",
    "\n",
    "def train():\n",
    "  \"\"\"Build Graph, launch session and train.\"\"\"\n",
    "\n",
    "  config = TrainConfig()\n",
    "  continue_train, ckpt_path, tflog_path, checkpoint = options(config)\n",
    "  g = tf.Graph()\n",
    "  with g.as_default():\n",
    "    loss, acc = model('train', config)\n",
    "    train_op, g_step, lr = optimizer(loss, config)\n",
    "    controller = TrainControl(lr)\n",
    "    # put variables in graph to hold validation acc and loss for TensorBoard viewing\n",
    "    val_acc = tf.Variable(0.0, trainable=False)\n",
    "    val_loss = tf.Variable(0.0, trainable=False)\n",
    "    tf.summary.scalar('val_loss', val_loss)\n",
    "    tf.summary.scalar('val_accuracy', val_acc)\n",
    "    init = tf.group(tf.global_variables_initializer(),\n",
    "                    tf.local_variables_initializer())\n",
    "    # histograms of all variables to TensorBoard\n",
    "    [tf.summary.histogram(v.name.replace(':', '_'), v)\n",
    "     for v in tf.trainable_variables()]\n",
    "    # next line only needed for batch normalization (updates beta and gamma)\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    summ = tf.summary.merge_all()\n",
    "    saver = tf.train.Saver(max_to_keep=1)\n",
    "    writer = tf.summary.FileWriter(tflog_path, g)\n",
    "    with tf.Session() as sess:\n",
    "      init.run()\n",
    "      if continue_train:\n",
    "        saver.restore(sess, checkpoint)\n",
    "      coord = tf.train.Coordinator()\n",
    "      threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "      try:\n",
    "        losses, accs = [], []  # hold running averages for test loss/acc\n",
    "        while not coord.should_stop():\n",
    "          step_loss, _, step, step_acc, __ = sess.run([loss, train_op,\n",
    "                                                       g_step, acc, extra_update_ops])\n",
    "          losses.append(step_loss)\n",
    "          accs.append(step_acc)\n",
    "          if step % config.eval_interval == 0:\n",
    "            ckpt = saver.save(sess, ckpt_path + '/model', step)\n",
    "            mean_loss, mean_acc = evaluate(ckpt)\n",
    "            val_acc.load(mean_acc)\n",
    "            val_loss.load(mean_loss)\n",
    "            controller.add_val_acc(mean_acc)\n",
    "            controller.update_lr(sess)\n",
    "            if controller.done():\n",
    "              break\n",
    "          if step % config.summary_interval == 0:\n",
    "            writer.add_summary(sess.run(summ), step)\n",
    "            print('Iteration: {}, Loss: {:.3f}, Accuracy: {:.4f}'.\n",
    "                  format(step, np.mean(losses), np.mean(accs)))\n",
    "            losses, accs = [], []\n",
    "      except tf.errors.OutOfRangeError as e:\n",
    "        coord.request_stop(e)\n",
    "      finally:\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
